{"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOx4oeMC3hTvxLyI9ZXkFLu","include_colab_link":true,"mount_file_id":"1yWAxW5Pe7WREzi42KucyDsCr7WO1nAQE","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7896780,"sourceType":"datasetVersion","datasetId":4637182}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/MnCSSJ4x/VR-MiniProject/blob/main/VR3b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"colab_type":"text","id":"view-in-github"}},{"cell_type":"code","source":"import torch \nfrom torch import optim, cuda\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import transforms, datasets, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n# from torchsummary import summary\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport math \nfrom torch.utils.data import Dataset, TensorDataset, random_split\nfrom torchvision import transforms\nfrom tqdm import tqdm \nimport tarfile\n!pip install imutils\n\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport argparse \nimport joblib\nimport cv2\nimport os\nimport time \nfrom imutils import paths\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import models\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelBinarizer\n# from tqdm import tqdm_notebook as tqdm\nfrom tqdm import tqdm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3L-gKiFhfaQd","outputId":"5f032a18-359e-4001-d83b-6846ea9a3816","execution":{"iopub.status.busy":"2024-03-22T16:47:14.787236Z","iopub.execute_input":"2024-03-22T16:47:14.787703Z","iopub.status.idle":"2024-03-22T16:47:43.505010Z","shell.execute_reply.started":"2024-03-22T16:47:14.787666Z","shell.execute_reply":"2024-03-22T16:47:43.503413Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting imutils\n  Downloading imutils-0.5.4.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25834 sha256=1cedae86ecd0ed5ec2f91d094eeea336fa82603fe5a57a5bfda609ae87676d51\n  Stored in directory: /root/.cache/pip/wheels/85/cf/3a/e265e975a1e7c7e54eb3692d6aa4e2e7d6a3945d29da46f2d7\nSuccessfully built imutils\nInstalling collected packages: imutils\nSuccessfully installed imutils-0.5.4\n","output_type":"stream"}]},{"cell_type":"code","source":"cuda = cuda.is_available()\nprint(f'Train on gpu: {cuda}')\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Id5jfouGfd1X","outputId":"d046b858-6f88-46cf-b04a-5c51a7f5dab7","execution":{"iopub.status.busy":"2024-03-22T16:47:43.507358Z","iopub.execute_input":"2024-03-22T16:47:43.508104Z","iopub.status.idle":"2024-03-22T16:47:43.515493Z","shell.execute_reply.started":"2024-03-22T16:47:43.508067Z","shell.execute_reply":"2024-03-22T16:47:43.514082Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Train on gpu: False\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dataset Used \nThe dataset we are planning to use is the caltech 101 dataset.  It consist of about 40 to 800 images per category. Most categories have about 50 images. Collected in September 2003 by Fei-Fei Li, Marco Andreetto, and Marc'Aurelio Ranzato. The size of each image is roughly 300 x 200 pixels. ","metadata":{"id":"xHoO2d5ChGtu"}},{"cell_type":"code","source":"image_paths = list(paths.list_images('/kaggle/input/bike-horse1'))","metadata":{"id":"2UIA0qTn68lN","execution":{"iopub.status.busy":"2024-03-22T16:47:43.516950Z","iopub.execute_input":"2024-03-22T16:47:43.517304Z","iopub.status.idle":"2024-03-22T16:47:43.639566Z","shell.execute_reply.started":"2024-03-22T16:47:43.517276Z","shell.execute_reply":"2024-03-22T16:47:43.638450Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = []\nlabels = []\nlabel_names = []\nfor image_path in image_paths:\n    label = image_path.split(os.path.sep)[-2]\n    if label == 'BACKGROUND_Google':\n        continue\n\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    data.append(image)\n    label_names.append(label)\n    labels.append(label)","metadata":{"id":"8MywKplt7PFa","execution":{"iopub.status.busy":"2024-03-22T16:47:43.643507Z","iopub.execute_input":"2024-03-22T16:47:43.643964Z","iopub.status.idle":"2024-03-22T16:47:45.747747Z","shell.execute_reply.started":"2024-03-22T16:47:43.643921Z","shell.execute_reply":"2024-03-22T16:47:45.746638Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)            ","metadata":{"execution":{"iopub.status.busy":"2024-03-22T16:47:45.749432Z","iopub.execute_input":"2024-03-22T16:47:45.750460Z","iopub.status.idle":"2024-03-22T16:47:45.755843Z","shell.execute_reply.started":"2024-03-22T16:47:45.750420Z","shell.execute_reply":"2024-03-22T16:47:45.754309Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data = np.array(data)\nlabels = np.array(labels)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dsTLCprK7MbP","outputId":"23b56b3c-5ab8-4f7c-db02-5382c4235169","execution":{"iopub.status.busy":"2024-03-22T16:47:45.757494Z","iopub.execute_input":"2024-03-22T16:47:45.758137Z","iopub.status.idle":"2024-03-22T16:47:46.256762Z","shell.execute_reply.started":"2024-03-22T16:47:45.758064Z","shell.execute_reply":"2024-03-22T16:47:46.253906Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels)\n","\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (179,) + inhomogeneous part."],"ename":"ValueError","evalue":"setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (179,) + inhomogeneous part.","output_type":"error"}]},{"cell_type":"markdown","source":"Labels are in string format and we need to get it to number format ","metadata":{"id":"w4BT2IYFEuDi"}},{"cell_type":"code","source":"lb = LabelBinarizer()\nlabels = lb.fit_transform(labels)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ZmcyiLlEsXi","outputId":"d74aaff2-e159-4885-d6f0-a5a1aa773a09","execution":{"iopub.status.busy":"2024-03-22T16:48:00.605896Z","iopub.execute_input":"2024-03-22T16:48:00.606337Z","iopub.status.idle":"2024-03-22T16:48:00.624945Z","shell.execute_reply.started":"2024-03-22T16:48:00.606306Z","shell.execute_reply":"2024-03-22T16:48:00.623984Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"(X, X_Validation , Y, Y_Validation) = train_test_split(data, labels, \n                                                    test_size=0.2,  \n                                                    stratify=labels,\n                                                    random_state=42)\n\n(x_train, x_test, y_train, y_test) = train_test_split(X, Y, \n                                                    test_size=0.25, \n                                                    random_state=42)\n\nprint(f\"x_train examples: {x_train.shape}\\nx_test examples: {x_test.shape}\\nX_Validation examples: {X_Validation.shape}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzjD1NvQ7uPl","outputId":"263544eb-1116-4b5e-c9ea-09d566bdded5","execution":{"iopub.status.busy":"2024-03-22T16:48:04.626851Z","iopub.execute_input":"2024-03-22T16:48:04.627330Z","iopub.status.idle":"2024-03-22T16:48:04.682955Z","shell.execute_reply.started":"2024-03-22T16:48:04.627295Z","shell.execute_reply":"2024-03-22T16:48:04.681461Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m (X, X_Validation , Y, Y_Validation) \u001b[38;5;241m=\u001b[39m train_test_split(data, labels, \n\u001b[1;32m      2\u001b[0m                                                     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \n\u001b[1;32m      3\u001b[0m                                                     stratify\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m      4\u001b[0m                                                     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m (x_train, x_test, y_train, y_test) \u001b[38;5;241m=\u001b[39m train_test_split(X, Y, \n\u001b[1;32m      7\u001b[0m                                                     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, \n\u001b[1;32m      8\u001b[0m                                                     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_train examples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mx_test examples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mX_Validation examples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_Validation\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'shape'","output_type":"error"}]},{"cell_type":"markdown","source":"We need to do transformations on the images from this dataset as the model we are intending to use is the AlexNet model trained on ImageNet where the image is of size 224x224. We rescale the image as well as noramise it based on imagenet standards. Other than that since images per class is too low we also try some data augmentation on the train set explictly ","metadata":{"id":"lTGmm3Y0iBd2"}},{"cell_type":"code","source":"train_transform = transforms.Compose(\n    [transforms.ToPILImage(),\n\t transforms.Resize((224, 224)),\n     transforms.RandomRotation((-30, 30)),\n     transforms.RandomHorizontalFlip(p=0.5),\n     transforms.RandomVerticalFlip(p=0.5),\n     transforms.ToTensor(),\n     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                          std=[0.229, 0.224, 0.225])])\nval_transform = transforms.Compose(\n    [transforms.ToPILImage(),\n\t transforms.Resize((224, 224)),\n     transforms.ToTensor(),\n     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                          std=[0.229, 0.224, 0.225])])","metadata":{"id":"a_e9BW0WAKFk","execution":{"iopub.status.busy":"2024-03-22T16:48:10.461538Z","iopub.execute_input":"2024-03-22T16:48:10.462125Z","iopub.status.idle":"2024-03-22T16:48:10.475743Z","shell.execute_reply.started":"2024-03-22T16:48:10.462082Z","shell.execute_reply":"2024-03-22T16:48:10.474249Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Custom Dataset class which allows us to apply transformations and create a dataset object to pass into dataloader ","metadata":{"id":"gydwNaKZAS79"}},{"cell_type":"code","source":"# custom dataset\nclass ImageDataset(Dataset):\n    def __init__(self, images, labels=None, transforms=None):\n        self.X = images\n        self.y = labels\n        self.transforms = transforms\n         \n    def __len__(self):\n        return (len(self.X))\n    \n    def __getitem__(self, i):\n        data = self.X[i][:]\n        \n        if self.transforms:\n            data = self.transforms(data)\n            \n        if self.y is not None:\n            return (data, self.y[i])\n        else:\n            return data","metadata":{"id":"Yq2UvovOAOAM","execution":{"iopub.status.busy":"2024-03-22T16:48:11.747329Z","iopub.execute_input":"2024-03-22T16:48:11.748188Z","iopub.status.idle":"2024-03-22T16:48:11.758646Z","shell.execute_reply.started":"2024-03-22T16:48:11.748138Z","shell.execute_reply":"2024-03-22T16:48:11.756856Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data = ImageDataset(x_train, y_train, train_transform)\nval_data = ImageDataset(X_Validation, Y_Validation, val_transform)\ntest_data = ImageDataset(x_test, y_test, val_transform)\n \n# dataloaders\ntrainloader = DataLoader(train_data, batch_size=16, shuffle=True)\nvalloader = DataLoader(val_data, batch_size=16, shuffle=True)\ntestloader = DataLoader(test_data, batch_size=16, shuffle=False)","metadata":{"id":"AN0k6jR5ARhG","execution":{"iopub.status.busy":"2024-03-22T16:48:12.346811Z","iopub.execute_input":"2024-03-22T16:48:12.347313Z","iopub.status.idle":"2024-03-22T16:48:12.354921Z","shell.execute_reply.started":"2024-03-22T16:48:12.347275Z","shell.execute_reply":"2024-03-22T16:48:12.353815Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Pre-trained Model Alexnet ","metadata":{"id":"ZXqGNYaSDLgf"}},{"cell_type":"code","source":"model = models.alexnet(pretrained=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TkdJX31YCIst","outputId":"7ecdb6de-d3ab-41bf-9382-74585cfec393","execution":{"iopub.status.busy":"2024-03-22T16:48:13.552079Z","iopub.execute_input":"2024-03-22T16:48:13.552476Z","iopub.status.idle":"2024-03-22T16:48:16.674145Z","shell.execute_reply.started":"2024-03-22T16:48:13.552445Z","shell.execute_reply":"2024-03-22T16:48:16.673174Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n100%|██████████| 233M/233M [00:01<00:00, 129MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtLQUvBUEbmf","outputId":"c7b45016-381c-4a7c-e805-aaa1140f56e6","execution":{"iopub.status.busy":"2024-03-22T16:48:16.676187Z","iopub.execute_input":"2024-03-22T16:48:16.676915Z","iopub.status.idle":"2024-03-22T16:48:16.685615Z","shell.execute_reply.started":"2024-03-22T16:48:16.676873Z","shell.execute_reply":"2024-03-22T16:48:16.684157Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False","metadata":{"id":"HaZDQLVief7B","execution":{"iopub.status.busy":"2024-03-22T16:48:16.688050Z","iopub.execute_input":"2024-03-22T16:48:16.688638Z","iopub.status.idle":"2024-03-22T16:48:16.697648Z","shell.execute_reply.started":"2024-03-22T16:48:16.688596Z","shell.execute_reply":"2024-03-22T16:48:16.696201Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.classifier[6] = nn.Linear(in_features=4096,out_features=101,bias=True)","metadata":{"id":"-lui0edrLRQk","execution":{"iopub.status.busy":"2024-03-22T16:48:16.701402Z","iopub.execute_input":"2024-03-22T16:48:16.701811Z","iopub.status.idle":"2024-03-22T16:48:16.717473Z","shell.execute_reply.started":"2024-03-22T16:48:16.701779Z","shell.execute_reply":"2024-03-22T16:48:16.716123Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for param in model.classifier[6].parameters():\n  param.requires_grad = True","metadata":{"id":"SiEKu4GgfxRb","execution":{"iopub.status.busy":"2024-03-22T16:48:16.719246Z","iopub.execute_input":"2024-03-22T16:48:16.719717Z","iopub.status.idle":"2024-03-22T16:48:16.727012Z","shell.execute_reply.started":"2024-03-22T16:48:16.719675Z","shell.execute_reply":"2024-03-22T16:48:16.725923Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NoaKJtk3NGb3","outputId":"7ce3a49a-b227-43bb-a944-7d4a11a0decf","execution":{"iopub.status.busy":"2024-03-22T16:48:16.729629Z","iopub.execute_input":"2024-03-22T16:48:16.730010Z","iopub.status.idle":"2024-03-22T16:48:16.743269Z","shell.execute_reply.started":"2024-03-22T16:48:16.729980Z","shell.execute_reply":"2024-03-22T16:48:16.742438Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=101, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0ZKg3_7FeFj","outputId":"f4962d1f-576f-4b22-93ea-6bdb8aafacb1","execution":{"iopub.status.busy":"2024-03-22T16:48:19.730745Z","iopub.execute_input":"2024-03-22T16:48:19.731146Z","iopub.status.idle":"2024-03-22T16:48:19.744801Z","shell.execute_reply.started":"2024-03-22T16:48:19.731116Z","shell.execute_reply":"2024-03-22T16:48:19.743456Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=101, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=0.01)\n# Define your loss function\ncriterion = nn.CrossEntropyLoss()","metadata":{"id":"dDFlmgpVD5S_","execution":{"iopub.status.busy":"2024-03-22T16:48:19.975264Z","iopub.execute_input":"2024-03-22T16:48:19.975645Z","iopub.status.idle":"2024-03-22T16:48:19.981439Z","shell.execute_reply.started":"2024-03-22T16:48:19.975616Z","shell.execute_reply":"2024-03-22T16:48:19.980406Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"epochs = 10 ","metadata":{"id":"6Sw_LklqEp8z","execution":{"iopub.status.busy":"2024-03-22T16:48:20.284463Z","iopub.execute_input":"2024-03-22T16:48:20.284931Z","iopub.status.idle":"2024-03-22T16:48:20.290311Z","shell.execute_reply.started":"2024-03-22T16:48:20.284897Z","shell.execute_reply":"2024-03-22T16:48:20.288972Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"#### Training and Validation ","metadata":{"id":"Bh6WXYhABNbR"}},{"cell_type":"code","source":"def fit(model, dataloader):\n    print('Training')\n    model.train()\n    Train_loss = 0.0\n    train_running_correct = 0\n    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n        data, target = data[0].to(device), data[1].to(device)\n        optimizer.zero_grad()\n        outputs = model(data)\n        loss = criterion(outputs, torch.max(target, 1)[1])\n        Train_loss += loss.item()\n        _, prediction = torch.max(outputs.data, 1)\n        train_running_correct += (prediction == torch.max(target, 1)[1]).sum().item()\n        loss.backward()\n        optimizer.step()\n        \n    Train_loss = Train_loss/len(dataloader.dataset)\n    Train_acc = 100. * train_running_correct/len(dataloader.dataset)\n    \n    print(f\"Train Loss: {Train_loss:.4f}, Train Acc: {Train_acc:.2f}\")\n    \n    return Train_loss, Train_acc","metadata":{"id":"EcY6sb7BBeYb","execution":{"iopub.status.busy":"2024-03-22T16:48:22.197512Z","iopub.execute_input":"2024-03-22T16:48:22.197900Z","iopub.status.idle":"2024-03-22T16:48:22.208788Z","shell.execute_reply.started":"2024-03-22T16:48:22.197871Z","shell.execute_reply":"2024-03-22T16:48:22.207310Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#validation function\ndef validate(model, dataloader):\n    print('Validating')\n    model.eval()\n    val_running_loss = 0.0\n    val_running_correct = 0\n    with torch.no_grad():\n        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n            data, target = data[0].to(device), data[1].to(device)\n            outputs = model(data)\n            loss = criterion(outputs, torch.max(target, 1)[1])\n            \n            val_running_loss += loss.item()\n            _, prediction = torch.max(outputs.data, 1)\n            val_running_correct += (prediction == torch.max(target, 1)[1]).sum().item()\n        \n        Validation_loss = val_running_loss/len(dataloader.dataset)\n        Validation_acc = 100. * val_running_correct/len(dataloader.dataset)\n        print(f'Val Loss: {Validation_loss:.4f}, Val Acc: {Validation_acc:.2f}')\n        \n        return Validation_loss, Validation_acc","metadata":{"id":"nXjROMH4Bby1","execution":{"iopub.status.busy":"2024-03-22T16:48:22.587495Z","iopub.execute_input":"2024-03-22T16:48:22.587953Z","iopub.status.idle":"2024-03-22T16:48:22.599041Z","shell.execute_reply.started":"2024-03-22T16:48:22.587918Z","shell.execute_reply":"2024-03-22T16:48:22.597658Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(f\"Training on {len(train_data)} examples, validating on {len(val_data)} examples\")\nTrain_loss , Train_acc = [], []\nValidation_loss , Validation_acc = [], []\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch+1} of {epochs}\")\n    Validation_epoch_loss, Validation_epoch_acc = validate(model, valloader)\n    train_epoch_loss, train_epoch_accuracy = fit(model, trainloader)\n    Validation_loss.append(Validation_epoch_loss)\n    Validation_acc.append(Validation_epoch_acc)\n    Train_acc.append(train_epoch_accuracy)\n    Train_loss.append(train_epoch_loss)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8IilTIRUBQDL","outputId":"d5640865-858c-4462-b1a0-89aea1d29228","execution":{"iopub.status.busy":"2024-03-22T16:48:23.083555Z","iopub.execute_input":"2024-03-22T16:48:23.083953Z","iopub.status.idle":"2024-03-22T16:48:55.478533Z","shell.execute_reply.started":"2024-03-22T16:48:23.083922Z","shell.execute_reply":"2024-03-22T16:48:55.477283Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Training on 107 examples, validating on 36 examples\nEpoch 1 of 10\nValidating\n","output_type":"stream"},{"name":"stderr","text":"3it [00:01,  3.00it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.3890, Val Acc: 0.00\nTraining\n","output_type":"stream"},{"name":"stderr","text":"7it [00:02,  2.95it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0489, Train Acc: 85.05\nEpoch 2 of 10\nValidating\n","output_type":"stream"},{"name":"stderr","text":"3it [00:00,  3.90it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.0000, Val Acc: 100.00\nTraining\n","output_type":"stream"},{"name":"stderr","text":"7it [00:02,  2.97it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0000, Train Acc: 100.00\nEpoch 3 of 10\nValidating\n","output_type":"stream"},{"name":"stderr","text":"3it [00:00,  3.88it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.0000, Val Acc: 100.00\nTraining\n","output_type":"stream"},{"name":"stderr","text":"7it [00:02,  3.03it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0000, Train Acc: 100.00\nEpoch 4 of 10\nValidating\n","output_type":"stream"},{"name":"stderr","text":"3it [00:00,  3.88it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.0000, Val Acc: 100.00\nTraining\n","output_type":"stream"},{"name":"stderr","text":"7it [00:02,  2.96it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0000, Train Acc: 100.00\nEpoch 5 of 10\nValidating\n","output_type":"stream"},{"name":"stderr","text":"3it [00:00,  3.92it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.0000, Val Acc: 100.00\nTraining\n","output_type":"stream"},{"name":"stderr","text":"7it [00:02,  2.70it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0000, Train Acc: 100.00\nEpoch 6 of 10\nValidating\n","output_type":"stream"},{"name":"stderr","text":"3it [00:00,  3.78it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.0000, Val Acc: 100.00\nTraining\n","output_type":"stream"},{"name":"stderr","text":"7it [00:02,  3.01it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0000, Train Acc: 100.00\nEpoch 7 of 10\nValidating\n","output_type":"stream"},{"name":"stderr","text":"3it [00:00,  3.74it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.0000, Val Acc: 100.00\nTraining\n","output_type":"stream"},{"name":"stderr","text":"7it [00:02,  3.01it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0000, Train Acc: 100.00\nEpoch 8 of 10\nValidating\n","output_type":"stream"},{"name":"stderr","text":"3it [00:00,  3.59it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.0000, Val Acc: 100.00\nTraining\n","output_type":"stream"},{"name":"stderr","text":"7it [00:02,  2.92it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0000, Train Acc: 100.00\nEpoch 9 of 10\nValidating\n","output_type":"stream"},{"name":"stderr","text":"3it [00:00,  3.87it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.0000, Val Acc: 100.00\nTraining\n","output_type":"stream"},{"name":"stderr","text":"7it [00:02,  3.01it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0000, Train Acc: 100.00\nEpoch 10 of 10\nValidating\n","output_type":"stream"},{"name":"stderr","text":"3it [00:01,  2.44it/s]                       \n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.0000, Val Acc: 100.00\nTraining\n","output_type":"stream"},{"name":"stderr","text":"7it [00:02,  2.94it/s]                       ","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0000, Train Acc: 100.00\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Test","metadata":{"id":"TTjOA2ucG8iP"}},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        inputs, target = data[0].to(device, non_blocking=True), data[1].to(device, non_blocking=True)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += target.size(0)\n        correct += (predicted == torch.max(target, 1)[1]).sum().item()\n\nprint('Accuracy of the network on test images: %0.3f %%' % (\n    100 * correct / total))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H7Z2IlnaG9XW","outputId":"655bcd8f-3afc-4b1b-c77e-17d7402ffd88","execution":{"iopub.status.busy":"2024-03-22T16:49:08.770114Z","iopub.execute_input":"2024-03-22T16:49:08.770539Z","iopub.status.idle":"2024-03-22T16:49:09.606796Z","shell.execute_reply.started":"2024-03-22T16:49:08.770510Z","shell.execute_reply":"2024-03-22T16:49:09.605584Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Accuracy of the network on test images: 100.000 %\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}